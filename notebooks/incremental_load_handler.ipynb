{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3c21174-77cc-4a46-8789-48cee578f4a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    season_id     team_id     game_id  game_date  ... blk tov  pf  plus_minus\n",
      "0       22024  1610612764  0022400341 2024-12-07  ...  12  17  21         9.0\n",
      "1       22024  1610612760  0022400342 2024-12-07  ...   3  18  24        10.0\n",
      "2       22024  1610612738  0022400345 2024-12-07  ...   7  13  16        -6.0\n",
      "3       22024  1610612752  0022400343 2024-12-07  ...   5  15  12        -9.0\n",
      "4       22024  1610612756  0022400346 2024-12-07  ...   3  14  20       -10.0\n",
      "5       22024  1610612766  0022400340 2024-12-07  ...   5  10  27       -14.0\n",
      "6       22024  1610612763  0022400345 2024-12-07  ...   7  13  25         6.0\n",
      "7       22024  1610612740  0022400342 2024-12-07  ...   6  18  20       -10.0\n",
      "8       22024  1610612739  0022400340 2024-12-07  ...   6  11  20        14.0\n",
      "9       22024  1610612743  0022400341 2024-12-07  ...   6  15  23        -9.0\n",
      "10      22024  1610612742  0022400344 2024-12-07  ...   8  18  16         7.0\n",
      "11      22024  1610612765  0022400343 2024-12-07  ...   0  18  20         9.0\n",
      "12      22024  1610612748  0022400346 2024-12-07  ...   4  11  20        10.0\n",
      "13      22024  1610612761  0022400344 2024-12-07  ...   3  13  22        -7.0\n",
      "\n",
      "[14 rows x 23 columns]\n",
      "        game_id     team_id  player_id  ...    pf   pts  plus_minus\n",
      "0    0022400341  1610612743    1631212  ...     3     4         -17\n",
      "1    0022400341  1610612743    1629008  ...     2    11         -10\n",
      "2    0022400341  1610612743     203999  ...     5    56          -1\n",
      "3    0022400341  1610612743    1631128  ...     3    14          -1\n",
      "4    0022400341  1610612743     201566  ...     5     7          -9\n",
      "..          ...         ...        ...  ...   ...   ...         ...\n",
      "174  0022400344  1610612761    1628449  ...  <NA>  <NA>        <NA>\n",
      "175  0022400344  1610612761    1642279  ...  <NA>  <NA>        <NA>\n",
      "176  0022400344  1610612761    1628981  ...  <NA>  <NA>        <NA>\n",
      "177  0022400344  1610612761    1642347  ...  <NA>  <NA>        <NA>\n",
      "178  0022400344  1610612761     202066  ...  <NA>  <NA>        <NA>\n",
      "\n",
      "[179 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import logging\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "# Import utility functions from utils.py\n",
    "from utils import (\n",
    "    get_game_logs,\n",
    "    process_game_logs,\n",
    "    get_boxscores,\n",
    "    process_boxscores\n",
    ")\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    \"\"\"\n",
    "    AWS Lambda handler function for incremental data ingestion.\n",
    "    This function:\n",
    "    - Fetches yesterday's NBA game logs.\n",
    "    - Processes game logs.\n",
    "    - Fetches and processes boxscores for those games.\n",
    "    \n",
    "    Parameters:\n",
    "    - event (dict): Event data that triggers the Lambda function.\n",
    "    - context (object): Provides runtime information to the handler.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Status message indicating success or failure.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Set date for API call (yesterday)\n",
    "        yesterday = datetime.now() - timedelta(days=1)\n",
    "        yesterday_str = yesterday.strftime('%m/%d/%Y')\n",
    "        logger.info(f\"Incremental load for NBA data game and box score data for {yesterday_str}\")\n",
    "\n",
    "        # Fetch game logs for yesterday\n",
    "        game_logs_df = get_game_logs(yesterday_str, yesterday_str)\n",
    "        if not game_logs_df.empty:\n",
    "            # Process the retrieved game logs\n",
    "            clean_game_logs_df = process_game_logs(game_logs_df)\n",
    "            print(clean_game_logs_df)\n",
    "            logger.info(f\"Retrieved and processed {len(clean_game_logs_df)} games.\")\n",
    "\n",
    "            # Fetch and process boxscores for each unique game\n",
    "            boxscores_list = []\n",
    "            unique_games = clean_game_logs_df['game_id'].unique()\n",
    "            for game_id in unique_games:\n",
    "                try:\n",
    "                    boxscore_df = get_boxscores(game_id)\n",
    "                    boxscores_list.append(boxscore_df)\n",
    "                    logger.info(f\"Box scores for game_id {game_id} retrieved successfully\")\n",
    "                except Exception as box_e:\n",
    "                    logger.error(f\"Failed to process box scores for game_id {game_id}: {str(box_e)}\")\n",
    "                    # Continue with the next game_id\n",
    "                    continue\n",
    "\n",
    "            if boxscores_list:\n",
    "                boxscores_df = pd.concat(boxscores_list, ignore_index=True)\n",
    "                clean_boxscores_df = process_boxscores(boxscores_df)\n",
    "                print(clean_boxscores_df)\n",
    "                # TODO: store_boxscores_in_rds(clean_boxscores_df)\n",
    "                # TODO: store_game_stats_in_rds(...) and store_games_in_rds(...) as needed\n",
    "                logger.info(f\"Processed boxscores for {len(boxscores_df)} records.\")\n",
    "            else:\n",
    "                logger.info('No boxscores found for yesterday.')\n",
    "\n",
    "        else:\n",
    "            logger.info('No games found for yesterday.')\n",
    "\n",
    "        return {\n",
    "            'statusCode': 200,\n",
    "            'body': json.dumps('Incremental data ingestion complete and stored successfully.')\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in lambda_handler: {str(e)}\")\n",
    "        return {\n",
    "            'statusCode': 500,\n",
    "            'body': json.dumps(f\"Data ingestion failed: {str(e)}\")\n",
    "        }\n",
    "    \n",
    "# Entry Point (for local testing)\n",
    "if __name__ == \"__main__\":\n",
    "    lambda_handler({}, {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2120b8d-ab46-47ac-ba0a-75d5cc91e3c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
